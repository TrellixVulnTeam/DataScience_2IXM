{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing the required libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy and pandas package\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the warnings\n",
    "import warnings\n",
    "\n",
    "# Import statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Import RMSE\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "\n",
    "# Import Decison Tree Regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Import train test split\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict, train\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import the metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Import Pre-Processing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# configuration settings\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)\n",
    "warnings.filterwarnings('ignore') ## Surpress the warnings\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('talk')\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (30, 10),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'}\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data into a dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data into a dataframe called supermarket_till_transactions_df\n",
    "supermarket_till_transactions_df = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the top five records\n",
    "supermarket_till_transactions_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to illustrate Support Vector Regression we just need two variables which are:\n",
    "1. SHOP_HOUR\n",
    "2. SPEND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supermarket_till_transactions_df = supermarket_till_transactions_df[[\"SHOP_HOUR\",\"SPEND\"]]\n",
    "supermarket_till_transactions_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = supermarket_till_transactions_df.iloc[:,:-1].values\n",
    "y = supermarket_till_transactions_df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into training and testing sets\n",
    "X, X_test, y, y_test = train_test_split(supermarket_till_transactions_df.iloc[:,0:-1],\n",
    "                                        supermarket_till_transactions_df.iloc[:,-1],\n",
    "                                        test_size=0.33,\n",
    "                                        random_state=42)\n",
    "#X.reset_index(inplace=True)\n",
    "#y = y.reset_index()\n",
    "\n",
    "#X_test.reset_index(inplace=True)\n",
    "#y_test = y_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = DecisionTreeRegressor(max_depth=4,\n",
    "                            min_samples_split=5,\n",
    "                            max_leaf_nodes=10)\n",
    "dtm.fit(X,y)\n",
    "print(\"R-Squared on train dataset={}\".format(dtm.score(X_test,y_test)))\n",
    "\n",
    "dtm.fit(X_test,y_test)\n",
    "print(\"R-Squared on test dataset={}\".format(dtm.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-parameter tuning with GridSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"criterion\": [\"mse\", \"mae\"],\n",
    "              \"min_samples_split\": [10, 20, 40],\n",
    "              \"max_depth\": [2, 6, 8],\n",
    "              \"min_samples_leaf\": [20, 40, 100],\n",
    "              \"max_leaf_nodes\": [5, 20, 100],\n",
    "             }\n",
    "\n",
    "grid_cv_dtm = GridSearchCV(dtm, param_grid, cv=5)\n",
    "\n",
    "grid_cv_dtm.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-Squared::{}\".format(grid_cv_dtm.best_score_))\n",
    "print(\"Best Hyperparameters::\\n{}\".format(grid_cv_dtm.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sns.pointplot(data=df[['mean_test_score',\n",
    "                       'param_max_leaf_nodes',\n",
    "                       'param_max_depth']],\n",
    "              y='mean_test_score',x='param_max_depth',\n",
    "              hue='param_max_leaf_nodes',ax=ax)\n",
    "ax.set(title=\"Effect of Depth and Leaf Nodes on Model Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the training model scores\n",
    "r2_scores = cross_val_score(grid_cv_dtm.best_estimator_, X, y, cv=10)\n",
    "mse_scores = cross_val_score(grid_cv_dtm.best_estimator_, X, y, cv=10,scoring='neg_mean_squ\n",
    "\n",
    "print(\"avg R-squared::{:.3f}\".format(np.mean(r2_scores)))\n",
    "print(\"MSE::{:.3f}\".format(np.mean(mse_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_dtm_model = grid_cv_dtm.best_estimator_\n",
    "\n",
    "y_pred = best_dtm_model.predict(X_test)\n",
    "\n",
    "r2_score = best_dtm_model.score(X_test,y_test)\n",
    "print(\"R-squared:{:.3f}\".format(r2_score))\n",
    "print(\"MSE: %.2f\" % metrics.mean_squared_error(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
