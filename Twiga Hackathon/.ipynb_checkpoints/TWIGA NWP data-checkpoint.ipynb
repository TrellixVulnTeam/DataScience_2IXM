{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical weather prediction data\n",
    "The following notebook elaborates on how to use the TWIGA API to retrieve and work with weather forecast data. Examples are based on the Unified Model for Southern Africa (below the equator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# Load some libraries       #\n",
    "#############################\n",
    "import shutil\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "# plot figures directly into the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# TWIGA API settings        #\n",
    "#############################\n",
    "\n",
    "# The HydroNET/TWIGA API endpoint\n",
    "api = 'https://hnapi.hydronet.com/api/'\n",
    "\n",
    "# The bearer token for the TWIGA user\n",
    "# this token is used to identify as a valid TWIGA user to the API\n",
    "api_token = 'eyJhbGciOiJSUzI1NiIsImtpZCI6ImIyY2I4NjU2NjNlY2RiYzEyMGZkOGViYzFkM2ExOGIwIiwidHlwIjoiSldUIn0.eyJuYmYiOjE1NzE4MzEzOTksImV4cCI6MTcyMzA2MjYyOSwiaXNzIjoiaHR0cHM6Ly9vaWRjLmh5ZHJvbmV0LmNvbSIsImF1ZCI6Imh0dHBzOi8vb2lkYy5oeWRyb25ldC5jb20vcmVzb3VyY2VzIiwiY2xpZW50X2lkIjoiaG40cy1wcm9kdWN0aW9uIiwiY2xpZW50X3Byb2ZpbGUiOiJwcm9maWxlIiwiY2xpZW50X2VtYWlsIjoiZW1haWwiLCJjbGllbnRfbmFtZSI6Im5hbWUiLCJjbGllbnRfc3RyaW5nIjoiaWRfdG9rZW4gdG9rZW4iLCJjbGllbnRfb2ZmbGluZV9hY2Nlc3MiOiJvZmZsaW5lX2FjY2VzcyIsInN1YiI6IjQzYmEwNjhjLTI3NzYtNDg1My1hYjc5LTIyMzIxMTE3NzZhMCIsImF1dGhfdGltZSI6MTU3MTgzMTM5OSwiaWRwIjoibG9jYWwiLCJqdGkiOiIyNTg1M2UwNjRjMGFhYjg2N2RmZTgyNjdjNzBmZTcyMCIsInNjb3BlIjpbIm9wZW5pZCIsInByb2ZpbGUiLCJvZmZsaW5lX2FjY2VzcyJdLCJhbXIiOlsicHdkIl19.PhkJ3SVi2ZjBEan9OlV9qpFAV3fqjsPQqQv-gk_ZtWlIuwTvoPMt5whwAa07opUNV5tO_-Jk4B8R-W9x2znMmzA_d9Bjyiwrwto3GgaUBBryXR-GIs21Dy1Hj62qUvUDpI07EQhGeq7SpxYeO0WdK_t-5U-3w3y9WNihvmcyfMsJukw9AOsSObEPUY6YUiTv71vbqKPQc55pbuPHpaDRHZITH0Nps3E_jrnwn9Aepz7B7MDVXyM_vU1Vb-MzAVZq03XvCf_YdWWxQUqPhbBVHcJjfzSQGrFl-8pGMLkHvcx1PgEnrxN9y7JS6tP_D7rZMBwA4vaiHXX5Z1XdBsvwYg'\n",
    "\n",
    "# Using the token, generate a valid header for requests to the API\n",
    "api_header = {'content-type': 'application/json', 'Authorization': 'bearer ' + api_token}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the available data sources\n",
    "The TWIGA api holds a lot of data. There are different data sources available, each containing relevant data for TWIGA. Using the API one can request data of any of the TWIGA data sources. If you know which datasource you are intersted in, you can direct request data from iw. However, often one of the first steps is to look into what data sources are available.\n",
    "\n",
    "Getting an overview of the different data sources can be done by sending a request to the 'datasources' endpoint of the TWIGA API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# an empty request which can be send to the TWIGA API\n",
    "datasource_metadata = {}\n",
    "\n",
    "# Send the request to the datasources endpoint of the API\n",
    "datasource_response = requests.post(api + 'entity/datasources/get', headers=api_header, data=json.dumps(datasource_metadata))\n",
    "\n",
    "# The response of the API is in JSON. Parse this with Python\n",
    "datasource_metadata = datasource_response.json()\n",
    "\n",
    "# print the result, as indented json\n",
    "print(json.dumps(datasource_metadata, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "Question 1, How many datasources are available in the TWIGA platform?\n",
    "hint, use the len() function of python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer space\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the response of the TWIGA API we can see that \n",
    "# one data source has the code Rain4Africa.SouthernAfrica.UnifiedModel.Deterministic.4km\n",
    "# this datasource is the NWP data below the equator\n",
    "# for the remainder of this notebook we will focus on this data source\n",
    "\n",
    "# store the selected data source code\n",
    "selected_datasource_code = \"Rain4Africa.SouthernAfrica.UnifiedModel.Deterministic.4km\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json request to ask metadata of a single datasource\n",
    "request_metadata_um = {\n",
    "     \"DataSourceCodes\": [selected_datasource_code]\n",
    "}\n",
    "\n",
    "# Send the request to the datasources endpoint of the API\n",
    "datasource_um_response = requests.post(api + 'entity/datasources/get', headers=api_header, data=json.dumps(request_metadata_um))\n",
    "\n",
    "# The response of the API is in JSON. Parse this with Python\n",
    "datasource_um_metadata = datasource_um_response.json()\n",
    "\n",
    "# print the result, as indented json\n",
    "print(json.dumps(datasource_um_metadata, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "Question 2, what is the temporal resolution of the Unified Model data?\n",
    "\n",
    "Question 3, how many forecast timesteps are there in a modelrun?\n",
    "\n",
    "Question 4, can you determine how often the UM is run per day?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answers space\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical weather models are continously updated. When we are going to request data, we want to\n",
    "# request data of the latest available model run\n",
    "\n",
    "# The latest available modelrun can be found in the previous response of the API\n",
    "# it is defined as the 'EndDate' of the data source\n",
    "\n",
    "# It is of course possible to write this down manually, but we can extract it directly\n",
    "# from the JSON response\n",
    "\n",
    "# the JSON response is nested, we can use this structure to get the value from 'EndDate'\n",
    "datasource_enddate_string = datasource_metadata['DataSources'].get(selected_datasource_code).get('EndDate')\n",
    "\n",
    "# the enddate is given as a string (text), in YYYYmmddHHMMSS\n",
    "# if we convert it into an actual datetime object, we can easily work with it in python\n",
    "datasource_enddate = datetime.datetime.strptime(datasource_enddate_string, '%Y%m%d%H%M%S')\n",
    "\n",
    "# Using the answers of question 2 and 3, we can determine up to what moment in the future the NWP has predictions\n",
    "# the temporal resultion is hourly, and there are up 72 hours time steps into the future\n",
    "# this means the Unified Model has a forecast horizon of 3 days ahead starting from the model time\n",
    "# so we can determine what the last available datetime will be\n",
    "last_model_timestamp = datasource_enddate + datetime.timedelta(days=3)\n",
    "\n",
    "\n",
    "print(last_model_timestamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know now that weather forecast data of the unified model is available up to 3 hours ahead\n",
    "# the Unified Model runs twice per day, and provides a forecast for 3 days ahead\n",
    "\n",
    "# it is also interesting to know in what area there is data available, as the Unified Model does not cover the entire globe\n",
    "# the spatial extent of the UM is encapsulated in the grid definition in the TWIGA API\n",
    "# you can find the grid definition in the JSON response above\n",
    "\n",
    "# please fill in the griddefinition ID on the place of the questionmark\n",
    "um_grid_definition_id = ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now request additional information on the spatial extent from the API using the grid definition\n",
    "# json request to ask metadata of a single datasource\n",
    "request_grid_um = {\n",
    "     \"GridDefinitionIds\": [um_grid_definition_id]\n",
    "}\n",
    "\n",
    "# Send the request to the griddefinitions endpoint of the API\n",
    "griddef_um_response = requests.post(api + 'entity/griddefinitions/get', headers=api_header, data=json.dumps(request_grid_um))\n",
    "\n",
    "# The response of the API is in JSON. Parse this with Python\n",
    "griddef_um_metadata = griddef_um_response.json()\n",
    "\n",
    "# print the result, as indented json\n",
    "print(json.dumps(griddef_um_metadata, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: plot extent on a map\n",
    "\n",
    "# in order to create some neat geogrpahic plots, python has the excellet cartopy package\n",
    "# this package is not installed by default. Using an anacond prompt, try to run the following command\n",
    "# conda install -c conda-forge cartopy\n",
    "\n",
    "# when successfull, we can load the cartopy packages\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get the XLL, XUR, YLL and YUR coordinates\n",
    "um_xll = griddef_um_metadata[\"Extents\"][str(um_grid_definition_id)].get(\"Xll\")\n",
    "um_xur = griddef_um_metadata[\"Extents\"][str(um_grid_definition_id)].get(\"Xur\")\n",
    "um_yll = griddef_um_metadata[\"Extents\"][str(um_grid_definition_id)].get(\"Yll\")\n",
    "um_yur = griddef_um_metadata[\"Extents\"][str(um_grid_definition_id)].get(\"Yur\")\n",
    "\n",
    "# create a plot of the spatial extent of the Unified Model\n",
    "plt.figure(figsize=(15, 9))\n",
    "central_lon, central_lat = (um_xll + um_xur) / 2, (um_yll + um_yur) / 2\n",
    "extent = [um_xll, um_xur, um_yll, um_yur]\n",
    "ax = plt.axes(projection=ccrs.Orthographic(central_lon, central_lat))\n",
    "ax.set_extent(extent)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "ax.add_feature(cartopy.feature.LAND, edgecolor='black')\n",
    "ax.add_feature(cartopy.feature.LAKES, edgecolor='black')\n",
    "ax.add_feature(cartopy.feature.RIVERS)\n",
    "ax.gridlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So far we have identified up to what point in time there is data available\n",
    "# we know for what region/location we have data available\n",
    "# the next step is to get look up for what variables there is data available\n",
    "\n",
    "\n",
    "# again we define a JSON request which we can send the the TWIGA API\n",
    "request_variables_um = {\n",
    "     \"DataSourceCodes\": [selected_datasource_code]\n",
    "}\n",
    "\n",
    "# This time we send the request to the variables endpoint of the API\n",
    "variables_um_response = requests.post(api + 'entity/variables/get', headers=api_header, data=json.dumps(request_variables_um))\n",
    "\n",
    "# The response of the API is in JSON. Parse this with Python\n",
    "variables_um_metadata = variables_um_response.json()\n",
    "\n",
    "# print the result, as indented json\n",
    "print(json.dumps(variables_um_metadata, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "What variables are available? \n",
    "Is data from relativy humidity available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have all the information we need, and we can proceed to retrieve actual data from the TWIGA api\n",
    "\n",
    "# first define a location, in lat/long. For example, Stellenbosch Jonkershoek Nature Reserve\n",
    "lat = -33.979423\n",
    "lon = 19.001196\n",
    "\n",
    "# specify a variable of interest, for example temperature\n",
    "# please note that you allways have to give the Code, this is the identifier used by the TWIGA platform\n",
    "variable_code_of_interest = \"TMP\"\n",
    "\n",
    "# We want to retrieve data of the latest available modelrun\n",
    "# formatted as a string YYYYmmddHHMMSS\n",
    "model_date = datasource_enddate.strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "# We want to retrieve all available time steps in the modelrun, so from the T=0 up to 3 days ahead\n",
    "start_date = model_date\n",
    "end_date = last_model_timestamp.strftime('%Y%m%d%H%M%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with all the information set, we can now build up the request we need to send to the TWIGA API\n",
    "request_for_data_unified_model = {\n",
    "     \"TimeZoneOffset\": \"+0000\",\n",
    "     \"Readers\": [{\n",
    "          \"DataSourceCode\": selected_datasource_code,\n",
    "          \"Settings\": {\n",
    "                \"ModelDate\": model_date,\n",
    "                \"StartDate\": start_date,\n",
    "                \"EndDate\": end_date,\n",
    "                \"VariableCodes\": [variable_code_of_interest],\n",
    "                \"ReadAccumulated\": \"false\",\n",
    "                \"Extent\": {\n",
    "                     \"XLL\": lon,\n",
    "                     \"YLL\": lat,\n",
    "                     \"XUR\": lon,\n",
    "                     \"YUR\": lat,\n",
    "                     \"SpatialReference\": {\n",
    "                          \"Epsg\": \"4326\"\n",
    "                     }\n",
    "                }\n",
    "          }\n",
    "     }]\n",
    "}\n",
    "\n",
    "\n",
    "# send the request to the TWIGA API, this time the modelTimeseries endpoint\n",
    "data_response = requests.post(api + 'modelTimeseries/get', headers=api_header, data=json.dumps(request_for_data_unified_model))\n",
    "\n",
    "# parse response into JSON object\n",
    "unified_model_data = data_response.json()\n",
    "\n",
    "# print the result, as indented json\n",
    "print(json.dumps(unified_model_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the result is a nested JSON object, it contains both the meta data and the actual data of interest\n",
    "# the actual data can be found in the 'Data' part of the JSON\n",
    "# it can be ingested into a pandas dataframe\n",
    "\n",
    "um_data = pd.DataFrame(unified_model_data['Data'][0]['Data'])\n",
    "\n",
    "# convert the DateTime from string into datetime objects\n",
    "um_data['DateTime'] = pd.to_datetime(um_data['DateTime'])\n",
    "\n",
    "print(um_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the Value column to the name of the variable\n",
    "um_data = um_data.rename(columns={\"Value\": variable_code_of_interest})\n",
    "\n",
    "# we can use this data frame to create a plot of the data\n",
    "um_data.plot(kind='line', x='DateTime', y=variable_code_of_interest, color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also store this data to your local computer in a csv file\n",
    "# please adjust the following line, to a valid location on your computer\n",
    "csv_file_location = \"C:/Some/Folder/temperature.csv\"\n",
    "\n",
    "# we can now save the data to a csv file on your local computer\n",
    "um_data.to_csv(\"C:/Temp/temperature_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously we requested data of temperature, but there are more variables available\n",
    "# we can use a loop to request data of multiple parameters\n",
    "multiple_variables_of_interest = [\"P\", \"TMP\", \"DPT\", \"TMIN\", \"TMAX\", \"WindSpeed\", \"WindDirection\", \"NCCC\"]\n",
    "\n",
    "# use a loop to retrieve data from the API\n",
    "for i in range(len(multiple_variables_of_interest)):\n",
    "    request_object = {\n",
    "         \"TimeZoneOffset\": \"+0000\",\n",
    "         \"Readers\": [{\n",
    "              \"DataSourceCode\": selected_datasource_code,\n",
    "              \"Settings\": {\n",
    "                    \"ModelDate\": model_date,\n",
    "                    \"StartDate\": start_date,\n",
    "                    \"EndDate\": end_date,\n",
    "                    \"VariableCodes\": [multiple_variables_of_interest[i]],\n",
    "                    \"ReadAccumulated\": \"false\",\n",
    "                    \"Extent\": {\n",
    "                         \"XLL\": lon,\n",
    "                         \"YLL\": lat,\n",
    "                         \"XUR\": lon,\n",
    "                         \"YUR\": lat,\n",
    "                         \"SpatialReference\": {\n",
    "                              \"Epsg\": \"4326\"\n",
    "                         }\n",
    "                    }\n",
    "              }\n",
    "         }]\n",
    "    }\n",
    "    # send the request to the TWIGA API\n",
    "    data_response = requests.post(api + 'modelTimeseries/get', headers=api_header, data=json.dumps(request_object))\n",
    "    unified_model_data = data_response.json()\n",
    "    # extract the data into a dataframe\n",
    "    um_values = pd.DataFrame(unified_model_data['Data'][0]['Data'])\n",
    "    # rename the value column to the name of the variable\n",
    "    um_values = um_values.rename(columns={\"Value\": multiple_variables_of_interest[i]})\n",
    "    if i == 0:\n",
    "        # convert the DateTime from string into datetime objects\n",
    "        um_values['DateTime'] = pd.to_datetime(um_values['DateTime'])\n",
    "        # create resulting dataframe in which to store all data\n",
    "        um_data = um_values[[\"DateTime\", multiple_variables_of_interest[i]]]\n",
    "    else:\n",
    "        # attach this column to the previously created data frame\n",
    "        um_data = pd.concat([um_data, um_values[[multiple_variables_of_interest[i]]]], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In some cases there are -9999 values in the dataframe\n",
    "# these values signal No Data values\n",
    "\n",
    "# we can replace these -999 values with actual no data values in python\n",
    "um_data.mask(um_data == -9999, inplace=True)\n",
    "\n",
    "# print the resulting data frame\n",
    "print(um_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "Can you figure out what the precipitation sum is?\n",
    "\n",
    "What is the mean wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Unified Model does not contain any data on relative humidity\n",
    "# But the RH can be calculated using the temperature (T) and dewpoint temperature (TD)\n",
    "def calc_relative_humidity(T, TD):\n",
    "    RH = []\n",
    "    b = 17.265\n",
    "    c = 243.04\n",
    "    for i in range(len(T)):\n",
    "        RH_value = 100 * np.exp((c * b * (TD[i] - T[i])) / ( (c + T[i]) * (c + TD[i])))\n",
    "        RH.append(RH_value)\n",
    "    return RH\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the relative humidity\n",
    "RH = calc_relative_humidity(T = um_data[\"TMP\"].tolist(), TD = um_data[\"DPT\"].tolist())\n",
    "\n",
    "# attach the relative humidity to the data frame\n",
    "um_data[\"RH\"] = RH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print final data frame\n",
    "print(um_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "Can you get the weather forecast data for Nairobi?\n",
    "\n",
    "Can you retrieve the solar radiation forecast for Johannesburg?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer space\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grids\n",
    "In all the examples above we have worked with time-series data of a singular gridcell/pixel\n",
    "It is however also possible to retrieve grids from the TWIGA API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in order to request a grid, rather than a single pixel we can adjust a previous request\n",
    "\n",
    "# previously when requestion data, we have the following request body\n",
    "request_for_data_unified_model = {\n",
    "     \"TimeZoneOffset\": \"+0000\",\n",
    "     \"Readers\": [{\n",
    "          \"DataSourceCode\": selected_datasource_code,\n",
    "          \"Settings\": {\n",
    "                \"ModelDate\": model_date,\n",
    "                \"StartDate\": start_date,\n",
    "                \"EndDate\": end_date,\n",
    "                \"VariableCodes\": [variable_code_of_interest],\n",
    "                \"ReadAccumulated\": \"false\",\n",
    "                \"Extent\": {\n",
    "                     \"XLL\": lon,\n",
    "                     \"YLL\": lat,\n",
    "                     \"XUR\": lon,\n",
    "                     \"YUR\": lat,\n",
    "                     \"SpatialReference\": {\n",
    "                          \"Epsg\": \"4326\"\n",
    "                     }\n",
    "                }\n",
    "          }\n",
    "     }]\n",
    "}\n",
    "\n",
    "# In order to retrieve actual gridded data, we can simply omit the Extent from the request\n",
    "# or adjust the values to get a part of the entire grid\n",
    "# and we need to add that the structuretype is now a grid\n",
    "request_griddata_unified_model = {\n",
    "     \"TimeZoneOffset\": \"+0000\",\n",
    "     \"Readers\": [{\n",
    "          \"DataSourceCode\": selected_datasource_code,\n",
    "          \"Settings\": {\n",
    "                \"StructureType\": \"ModelGrid\",\n",
    "                \"ModelDate\": model_date,\n",
    "                \"StartDate\": start_date,\n",
    "                \"EndDate\": end_date,\n",
    "                \"VariableCodes\": [variable_code_of_interest],\n",
    "                \"ReadAccumulated\": \"false\"\n",
    "          }\n",
    "     }]\n",
    "}\n",
    "\n",
    "# We also need to adjust the start or enddate\n",
    "# Because we only want to request a single grid of one time step\n",
    "\n",
    "last_model_timestamp = datasource_enddate + datetime.timedelta(days=3)\n",
    "previous_timestamp = last_model_timestamp - datetime.timedelta(hours=1)\n",
    "\n",
    "request_griddata_unified_model = {\n",
    "     \"TimeZoneOffset\": \"+0000\",\n",
    "     \"Readers\": [{\n",
    "          \"DataSourceCode\": selected_datasource_code,\n",
    "          \"Settings\": {\n",
    "                \"StructureType\": \"ModelGrid\",\n",
    "                \"ModelDate\": model_date,\n",
    "                \"StartDate\": previous_timestamp.strftime('%Y%m%d%H%M%S'),\n",
    "                \"EndDate\": last_model_timestamp.strftime('%Y%m%d%H%M%S'),\n",
    "                \"VariableCodes\": [variable_code_of_interest],\n",
    "                \"ReadAccumulated\": \"false\"\n",
    "          }\n",
    "     }]\n",
    "}\n",
    "\n",
    "# By default the TWIGA api will return data in json format\n",
    "# but we can change this, to ask for a geotiff file instead\n",
    "request_griddata_unified_model = {\n",
    "     \"TimeZoneOffset\": \"+0000\",\n",
    "     \"Readers\": [{\n",
    "          \"DataSourceCode\": selected_datasource_code,\n",
    "          \"Settings\": {\n",
    "                \"StructureType\": \"ModelGrid\",\n",
    "                \"ModelDate\": model_date,\n",
    "                \"StartDate\": previous_timestamp.strftime('%Y%m%d%H%M%S'),\n",
    "                \"EndDate\": last_model_timestamp.strftime('%Y%m%d%H%M%S'),\n",
    "                \"VariableCodes\": [variable_code_of_interest],\n",
    "                \"ReadAccumulated\": \"false\"\n",
    "          }\n",
    "     }],\n",
    "     \"Exporter\": {\n",
    "          \"DataFormatCode\": \"geotiff\"\n",
    "     }\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send the request to the TWIGA API, this time the data endpoint\n",
    "data_grid_response = requests.post(api + 'data/get', headers=api_header, data=json.dumps(request_griddata_unified_model))\n",
    "\n",
    "# the response now hold the geotiff file, save this to your local computer\n",
    "store_geotiff = \"C:/Temp/unified_model_tempetature.tif\"\n",
    "with open(store_geotiff, 'wb') as f:\n",
    "    f.write(data_grid_response.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now load and plot the geotiff using the rasterio package\n",
    "import rasterio\n",
    "\n",
    "# load geotiff\n",
    "src = rasterio.open(store_geotiff)\n",
    "# plot the geotiff\n",
    "plt.imshow(src.read(1), cmap='pink')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "Can you make a plot of the cloudcover, for tomorrow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "Can you make a plot of the precipitation sum of the entire 3 days?\n",
    "\n",
    "Hint, add the following to the settings part of the request\n",
    "\t\t\t\"Interval\": {\n",
    "\t\t\t\t\"Type\": \"Total\",\n",
    "\t\t\t\t\"Value\": 0\n",
    "\t\t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "Can you retrieve the precipitation sum of the Saws.Satellit product, for the month of october?\n",
    "And can you also make a plot of the result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
